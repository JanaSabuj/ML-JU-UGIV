{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31117,
     "status": "ok",
     "timestamp": 1635079372727,
     "user": {
      "displayName": "lakshya bengani",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjeGCjrct2M6RQ5IepwzvkNJTrJKXf2zI3_e9PcqQ=s64",
      "userId": "13179502610213181202"
     },
     "user_tz": -330
    },
    "id": "DLlu0CJ5jbEI",
    "outputId": "852babdc-ffd8-47a5-a788-7a05463dc5f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMBOVKos6MmJ"
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import argparse\n",
    "\n",
    "# Import necessary components to build LeNet\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import skimage.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rNvs7q8a6RxC"
   },
   "outputs": [],
   "source": [
    "def alexnet_model(img_shape=(224, 224, 3), n_classes=10, l2_reg=0.,\n",
    "\tweights=None):\n",
    "\n",
    "\t# Initialize model\n",
    "\talexnet = Sequential()\n",
    "\n",
    "\t# Layer 1\n",
    "\talexnet.add(Conv2D(30, (11, 11), input_shape=img_shape,\n",
    "\t\tpadding='same', kernel_regularizer=l2(l2_reg)))\n",
    "\talexnet.add(BatchNormalization())\n",
    "\talexnet.add(Activation('relu'))\n",
    "\talexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t# Layer 2\n",
    "\talexnet.add(Conv2D(30, (5, 5), padding='same'))\n",
    "\talexnet.add(BatchNormalization())\n",
    "\talexnet.add(Activation('relu'))\n",
    "\talexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t# Layer 3\n",
    "\talexnet.add(ZeroPadding2D((1, 1)))\n",
    "\talexnet.add(Conv2D(30, (3, 3), padding='same'))\n",
    "\talexnet.add(BatchNormalization())\n",
    "\talexnet.add(Activation('relu'))\n",
    "\talexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t# Layer 4\n",
    "\talexnet.add(ZeroPadding2D((1, 1)))\n",
    "\talexnet.add(Conv2D(30, (3, 3), padding='same'))\n",
    "\talexnet.add(BatchNormalization())\n",
    "\talexnet.add(Activation('relu'))\n",
    "\n",
    "\t# Layer 5\n",
    "\talexnet.add(ZeroPadding2D((1, 1)))\n",
    "\talexnet.add(Conv2D(30, (3, 3), padding='same'))\n",
    "\talexnet.add(BatchNormalization())\n",
    "\talexnet.add(Activation('relu'))\n",
    "\talexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t# Layer 6\n",
    "\talexnet.add(Flatten())\n",
    "\talexnet.add(Dense(30))\n",
    "\talexnet.add(BatchNormalization())\n",
    "\talexnet.add(Activation('relu'))\n",
    "\talexnet.add(Dropout(0.5))\n",
    "\n",
    "\t# Layer 7\n",
    "\talexnet.add(Dense(30))\n",
    "\talexnet.add(BatchNormalization())\n",
    "\talexnet.add(Activation('relu'))\n",
    "\talexnet.add(Dropout(0.5))\n",
    "\n",
    "\t# Layer 8\n",
    "\talexnet.add(Dense(n_classes))\n",
    "\talexnet.add(BatchNormalization())\n",
    "\talexnet.add(Activation('softmax'))\n",
    "\n",
    "\tif weights is not None:\n",
    "\t\talexnet.load_weights(weights)\n",
    "\n",
    "\treturn alexnet\n",
    "\n",
    "def parse_args():\n",
    "\t\"\"\"\n",
    "\tParse command line arguments.\n",
    "\tParameters:\n",
    "\t\tNone\n",
    "\tReturns:\n",
    "\t\tparser arguments\n",
    "\t\"\"\"\n",
    "\tparser = argparse.ArgumentParser(description='AlexNet model')\n",
    "\toptional = parser._action_groups.pop()\n",
    "\trequired = parser.add_argument_group('required arguments')\n",
    "\toptional.add_argument('--print_model',\n",
    "\t\tdest='print_model',\n",
    "\t\thelp='Print AlexNet model',\n",
    "\t\taction='store_true')\n",
    "\tparser._action_groups.append(optional)\n",
    "\treturn parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-I9hTl87Z6E"
   },
   "outputs": [],
   "source": [
    "def load_preprocess_training_batch(X_train):\n",
    "    \n",
    "    new = []\n",
    "    \n",
    "    for item in X_train:\n",
    "        tmpFeature = skimage.transform.resize(item, (224, 224), mode='constant')\n",
    "        new.append(tmpFeature)\n",
    "\n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2TmDo7kUmnS"
   },
   "source": [
    "# CIFAR 10 DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YRMAVVkm7L6y"
   },
   "outputs": [],
   "source": [
    "# Command line parameters\n",
    "# args = parse_args()\n",
    "\n",
    "# Create AlexNet model\n",
    "model = alexnet_model()\n",
    "\n",
    "# Print\n",
    "# if args.print_model:\n",
    "# \tmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQ2uuURi86GQ"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train) , (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "X_train = X_train[0:500]\n",
    "y_train = y_train[0:500]\n",
    "X_test = X_test[0:200]\n",
    "y_test = y_test[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w7JZqOmw9DYn"
   },
   "outputs": [],
   "source": [
    "X_train_resized = load_preprocess_training_batch(X_train)\n",
    "X_test_resized = load_preprocess_training_batch(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2xHCuhNv9O-I"
   },
   "outputs": [],
   "source": [
    "X_train_resized = np.array(X_train_resized)\n",
    "X_test_resized = np.array(X_test_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMpBtT5t9WQ_"
   },
   "outputs": [],
   "source": [
    "X_train_resized = X_train_resized / 255\n",
    "X_test_resized = X_test_resized / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 323821,
     "status": "ok",
     "timestamp": 1635006725726,
     "user": {
      "displayName": "Pritesh Sahani",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDGHdTtav_jgv7976F4wM1Z56HG42YtCp9J1KG=s64",
      "userId": "17183347222361440423"
     },
     "user_tz": -330
    },
    "id": "S0QYAVF_9YDG",
    "outputId": "c9420444-9ad5-4273-e592-0474825beb36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16/16 [==============================] - 61s 4s/step - loss: 2.6788 - accuracy: 0.1240\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 59s 4s/step - loss: 2.6332 - accuracy: 0.0960\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 60s 4s/step - loss: 2.5360 - accuracy: 0.1220\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 59s 4s/step - loss: 2.4222 - accuracy: 0.1400\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 60s 4s/step - loss: 2.3684 - accuracy: 0.1400\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_resized, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6066,
     "status": "ok",
     "timestamp": 1635006817907,
     "user": {
      "displayName": "Pritesh Sahani",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgDGHdTtav_jgv7976F4wM1Z56HG42YtCp9J1KG=s64",
      "userId": "17183347222361440423"
     },
     "user_tz": -330
    },
    "id": "ko1in3vw9hXz",
    "outputId": "83221020-a68a-4101-827f-27611bd8bded"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 6s 753ms/step - loss: 2.3611 - accuracy: 0.0750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3610661029815674, 0.07500000298023224]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_resized, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4cxjULYUxwv"
   },
   "source": [
    "# NMIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dj_OBI3hU69G"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train) , (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train = X_train[0:2000]\n",
    "y_train = y_train[0:2000]\n",
    "X_test = X_test[0:2000]\n",
    "y_test = y_test[0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zB7e7K7lVsfX"
   },
   "outputs": [],
   "source": [
    "X_train_resized = load_preprocess_training_batch(X_train)\n",
    "X_test_resized = load_preprocess_training_batch(X_test)\n",
    "\n",
    "X_train_resized = np.array(X_train_resized)\n",
    "X_test_resized = np.array(X_test_resized)\n",
    "\n",
    "X_train_resized = X_train_resized / 255.0\n",
    "X_test_resized = X_test_resized / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_iuex7NWaxH"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "X_train_new = list()\n",
    "\n",
    "for i in range(len(X_train_resized)):\n",
    "  g  = X_train_resized[i]\n",
    "  X_train_new.append(cv2.merge([g,g,g]))\n",
    "\n",
    "X_train_new = np.asarray(X_train_new,dtype=np.float32)\n",
    "\n",
    "X_test_new = list()\n",
    "\n",
    "for i in range(len(X_test_resized)):\n",
    "  g  = X_test_resized[i]\n",
    "  X_test_new.append(cv2.merge([g,g,g]))\n",
    "\n",
    "X_test_new = np.asarray(X_test_new,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2364372,
     "status": "ok",
     "timestamp": 1635065451068,
     "user": {
      "displayName": "lakshya bengani",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjeGCjrct2M6RQ5IepwzvkNJTrJKXf2zI3_e9PcqQ=s64",
      "userId": "13179502610213181202"
     },
     "user_tz": -330
    },
    "id": "qT3uaXDxWkZH",
    "outputId": "8eef741f-dde1-4424-cb19-ef7219a7c525"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "63/63 [==============================] - 474s 8s/step - loss: 2.0734 - accuracy: 0.2610\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 476s 8s/step - loss: 1.7821 - accuracy: 0.3680\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 468s 7s/step - loss: 1.6773 - accuracy: 0.4395\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 469s 7s/step - loss: 1.5820 - accuracy: 0.4810\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 472s 7s/step - loss: 1.5318 - accuracy: 0.5040\n"
     ]
    }
   ],
   "source": [
    "model = alexnet_model()\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_new, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 142550,
     "status": "ok",
     "timestamp": 1635066422876,
     "user": {
      "displayName": "lakshya bengani",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjeGCjrct2M6RQ5IepwzvkNJTrJKXf2zI3_e9PcqQ=s64",
      "userId": "13179502610213181202"
     },
     "user_tz": -330
    },
    "id": "xRj8O1-0W-Vv",
    "outputId": "17b31b56-4c17-472f-ee1a-4e1723dff461"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 107s 2s/step - loss: 2.3417 - accuracy: 0.1170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3417277336120605, 0.11699999868869781]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_new, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MafQRAVJXLJP"
   },
   "source": [
    "# SAVEE Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MHrR_A7RXAWf"
   },
   "outputs": [],
   "source": [
    "!unzip \"/content/drive/MyDrive/SaveeDataset.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UDvIwGlLXRqm"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "input_length = 16000*5\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "n_mels = 320\n",
    "\n",
    "def preprocess_audio_mel_T(audio, sample_rate=16000, window_size=20, #log_specgram\n",
    "                 step_size=10, eps=1e-10):\n",
    "\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels= n_mels)\n",
    "    mel_db = (librosa.power_to_db(mel_spec, ref=np.max) + 40)/40\n",
    "\n",
    "    return mel_db.T\n",
    "\n",
    "\n",
    "def load_audio_file(file_path, input_length=input_length):\n",
    "  data = librosa.core.load(file_path, sr=16000)[0] #, sr=16000\n",
    "  if len(data)>input_length:\n",
    "    max_offset = len(data)-input_length\n",
    "    \n",
    "    offset = np.random.randint(max_offset)\n",
    "    \n",
    "    data = data[offset:(input_length+offset)]\n",
    "            \n",
    "  else:\n",
    "    if input_length > len(data):\n",
    "      max_offset = input_length - len(data)\n",
    "\n",
    "      offset = np.random.randint(max_offset)\n",
    "    else:\n",
    "      offset = 0\n",
    "    data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "    \n",
    "  data = preprocess_audio_mel_T(data)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W0RenEOFXTuf"
   },
   "outputs": [],
   "source": [
    "# Preprocessing the dataset\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "rootDirectory = \"/content/AudioData/\"\n",
    "personNames = [\"DC\",\"JE\",\"JK\",\"KL\"]\n",
    "\n",
    "classes = [\"a\" , \"d\" , \"f\", \"h\", \"n\", \"sa\" , \"su\" ]\n",
    "\n",
    "X = list()\n",
    "y = list()\n",
    "\n",
    "for person in personNames:\n",
    "  directory = os.path.join(rootDirectory,person)\n",
    "  for filename in os.listdir(directory):\n",
    "    filePath = os.path.join(directory, filename)\n",
    "    a = load_audio_file(file_path=filePath)\n",
    "    data = cv2.merge([a,a,a])\n",
    "    if(filename[0:1] in classes):\n",
    "      X.append(data)\n",
    "      y.append(classes.index(filename[0:1]))\n",
    "    elif(filename[0:2] in classes):\n",
    "      X.append(data)\n",
    "      y.append(classes.index(filename[0:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cTiaY5ufXXB2"
   },
   "outputs": [],
   "source": [
    "X = np.asarray(X, dtype=np.float32)\n",
    "y = np.asarray(y, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fMNhx4VjXYlm"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# dataset preparation\n",
    "\n",
    "from tensorflow.keras import datasets,layers,models\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, train_size= 0.5 ,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vpdgRy4yXaQ3"
   },
   "outputs": [],
   "source": [
    "X_train_resized = load_preprocess_training_batch(X_train)\n",
    "X_test_resized = load_preprocess_training_batch(X_test)\n",
    "\n",
    "X_train_resized = np.array(X_train_resized)\n",
    "X_test_resized = np.array(X_test_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 663967,
     "status": "ok",
     "timestamp": 1635068556757,
     "user": {
      "displayName": "lakshya bengani",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjeGCjrct2M6RQ5IepwzvkNJTrJKXf2zI3_e9PcqQ=s64",
      "userId": "13179502610213181202"
     },
     "user_tz": -330
    },
    "id": "ABaDUn1pXgjH",
    "outputId": "a2d37b52-c318-4af4-b330-adad18396483"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 99s 7s/step - loss: 2.6041 - accuracy: 0.1167\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 56s 7s/step - loss: 2.5481 - accuracy: 0.1167\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 57s 7s/step - loss: 2.4258 - accuracy: 0.1958\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 56s 7s/step - loss: 2.4215 - accuracy: 0.1583\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 56s 7s/step - loss: 2.2042 - accuracy: 0.2333\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 57s 7s/step - loss: 2.2080 - accuracy: 0.2042\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 56s 7s/step - loss: 2.1114 - accuracy: 0.2792\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 57s 7s/step - loss: 2.1120 - accuracy: 0.2542\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 56s 7s/step - loss: 2.0292 - accuracy: 0.2583\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 57s 7s/step - loss: 2.1150 - accuracy: 0.2417\n"
     ]
    }
   ],
   "source": [
    "model = alexnet_model()\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_resized, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20594,
     "status": "ok",
     "timestamp": 1635068578371,
     "user": {
      "displayName": "lakshya bengani",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjeGCjrct2M6RQ5IepwzvkNJTrJKXf2zI3_e9PcqQ=s64",
      "userId": "13179502610213181202"
     },
     "user_tz": -330
    },
    "id": "GHaUnU32Xg--",
    "outputId": "5d4c0fbc-0a19-4120-9af7-20e90f7785cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 13s 2s/step - loss: 2.2758 - accuracy: 0.2375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.275780200958252, 0.23749999701976776]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_resized, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IjKlohiZSjn"
   },
   "source": [
    "# EmoDB Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_aNb0QAn3Y-"
   },
   "outputs": [],
   "source": [
    "!unzip \"/content/drive/MyDrive/EmoDB.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dBcBA361n8qd"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "input_length = 16000*5\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "n_mels = 320\n",
    "\n",
    "def preprocess_audio_mel_T(audio, sample_rate=16000, window_size=20, #log_specgram\n",
    "                 step_size=10, eps=1e-10):\n",
    "\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels= n_mels)\n",
    "    mel_db = (librosa.power_to_db(mel_spec, ref=np.max) + 40)/40\n",
    "\n",
    "    return mel_db.T\n",
    "\n",
    "\n",
    "def load_audio_file(file_path, input_length=input_length):\n",
    "  data = librosa.core.load(file_path, sr=16000)[0] #, sr=16000\n",
    "  if len(data)>input_length:\n",
    "    max_offset = len(data)-input_length\n",
    "    \n",
    "    offset = np.random.randint(max_offset)\n",
    "    \n",
    "    data = data[offset:(input_length+offset)]\n",
    "            \n",
    "  else:\n",
    "    if input_length > len(data):\n",
    "      max_offset = input_length - len(data)\n",
    "\n",
    "      offset = np.random.randint(max_offset)\n",
    "    else:\n",
    "      offset = 0\n",
    "    data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "    \n",
    "  data = preprocess_audio_mel_T(data)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xC7x1Eun-nV"
   },
   "outputs": [],
   "source": [
    "# Preprocessing the dataset\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "directory = \"/content/wav/\"\n",
    "\n",
    "classes = [\"W\" ,\"L\" ,\"E\" ,\"A\" , \"F\" ,\"T\" ,\"N\" ]\n",
    "\n",
    "X = list()\n",
    "y = list()\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "  filePath = os.path.join(directory, filename)\n",
    "  a = load_audio_file(file_path=filePath)\n",
    "  data = cv2.merge([a,a,a])\n",
    "  if(filename[5:6] in classes):\n",
    "    X.append(data)\n",
    "    y.append(classes.index(filename[5:6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQBMSTM3sS-O"
   },
   "outputs": [],
   "source": [
    "X = np.asarray(X, dtype=np.float32)\n",
    "y = np.asarray(y, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3CCtN-veoArO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# dataset preparation\n",
    "\n",
    "from tensorflow.keras import datasets,layers,models\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, train_size= 0.6 ,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLjmziVOoFbl"
   },
   "outputs": [],
   "source": [
    "X_train_resized = load_preprocess_training_batch(X_train)\n",
    "X_test_resized = load_preprocess_training_batch(X_test)\n",
    "\n",
    "X_train_resized = np.array(X_train_resized)\n",
    "X_test_resized = np.array(X_test_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 757865,
     "status": "ok",
     "timestamp": 1635069526377,
     "user": {
      "displayName": "lakshya bengani",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjeGCjrct2M6RQ5IepwzvkNJTrJKXf2zI3_e9PcqQ=s64",
      "userId": "13179502610213181202"
     },
     "user_tz": -330
    },
    "id": "7FlxLoSooX-G",
    "outputId": "a24d1915-4a1e-47a6-f67a-cfe6f7ed37e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 78s 7s/step - loss: 2.6594 - accuracy: 0.0997\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 75s 7s/step - loss: 2.4658 - accuracy: 0.1121\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 75s 7s/step - loss: 2.4722 - accuracy: 0.1402\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 75s 7s/step - loss: 2.3171 - accuracy: 0.1776\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 75s 7s/step - loss: 2.2610 - accuracy: 0.1838\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 75s 7s/step - loss: 2.1741 - accuracy: 0.2025\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 77s 7s/step - loss: 2.0738 - accuracy: 0.2336\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 76s 7s/step - loss: 2.0492 - accuracy: 0.2679\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 76s 7s/step - loss: 2.0359 - accuracy: 0.2679\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 76s 7s/step - loss: 1.9726 - accuracy: 0.3115\n"
     ]
    }
   ],
   "source": [
    "model = alexnet_model()\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_resized, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11909,
     "status": "ok",
     "timestamp": 1635069539516,
     "user": {
      "displayName": "lakshya bengani",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjeGCjrct2M6RQ5IepwzvkNJTrJKXf2zI3_e9PcqQ=s64",
      "userId": "13179502610213181202"
     },
     "user_tz": -330
    },
    "id": "-VVU2ox_ocMn",
    "outputId": "fdb636e8-debb-47b3-91c8-ccc638bc9231",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 12s 2s/step - loss: 2.1748 - accuracy: 0.2336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.1748006343841553, 0.23364485800266266]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_resized, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "AlexNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
